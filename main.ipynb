{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt to model=/home/marwa/MaskDetectionYolo8/yolov8m.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084a1c58c0e64d0985bfe17b98a40cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/49.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model =YOLO('model=/home/marwa/MaskDetectionYolo8/yolov8m.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.74 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.58 ðŸš€ Python-3.8.10 torch-1.7.0+cu101 CUDA:0 (NVIDIA GeForce GTX 1080, 8111MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=model=/home/marwa/MaskDetectionYolo8/yolov8m.pt, data=/home/marwa/handGestur_yolov8/data.yaml, epochs=50, patience=50, batch=1, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolovm_train, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/yolovm_train2\n",
      "Overriding model.yaml nc=80 with nc=26\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.Conv                  [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.Conv                  [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.C2f                   [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.Conv                  [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.C2f                   [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.Conv                  [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.C2f                   [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.Conv                  [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.C2f                   [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.SPPF                  [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.C2f                   [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.C2f                   [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.Conv                  [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.C2f                   [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.Conv                  [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.C2f                   [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3790750  ultralytics.nn.modules.Detect                [26, [192, 384, 576]]         \n",
      "Model summary: 295 layers, 25871374 parameters, 25871358 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/yolovm_train2', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c73703c75247fd89bb7b9ff554e31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/6.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/marwa/handGestur_yolov8/train/labels... 3045 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [00:01<00:00, 2786.24it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/marwa/handGestur_yolov8/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/marwa/handGestur_yolov8/valid/labels... 675 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 675/675 [00:00<00:00, 2677.01it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/marwa/handGestur_yolov8/valid/labels.cache\n",
      "Plotting labels to runs/detect/yolovm_train2/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/yolovm_train2\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50     0.908G      1.566      4.651      1.853          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [06:23<00:00,  7.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.66it/s]\n",
      "                   all        675        680     0.0979      0.249      0.117      0.073\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50     0.956G      1.363      3.238      1.652          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [06:08<00:00,  8.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:19<00:00, 16.97it/s]\n",
      "                   all        675        680      0.211      0.355      0.214      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50     0.956G      1.408      2.905      1.664          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:44<00:00,  8.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.58it/s]\n",
      "                   all        675        680      0.167      0.376      0.198      0.113\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50     0.956G      1.463      2.824      1.713          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:38<00:00,  8.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.63it/s]\n",
      "                   all        675        680        0.2      0.456      0.219      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50     0.958G      1.477      2.756       1.73          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:39<00:00,  8.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.40it/s]\n",
      "                   all        675        680      0.244      0.441      0.256       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50      0.96G      1.411      2.578      1.711          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:39<00:00,  8.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.61it/s]\n",
      "                   all        675        680      0.356      0.509      0.397      0.222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/50      0.96G      1.385      2.441      1.668          0        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:40<00:00,  8.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.59it/s]\n",
      "                   all        675        680      0.317      0.498      0.361      0.216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/50      0.96G      1.359      2.285      1.635          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:40<00:00,  8.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.61it/s]\n",
      "                   all        675        680      0.386      0.487      0.379      0.228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/50      0.96G      1.334       2.18       1.63          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:41<00:00,  8.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.59it/s]\n",
      "                   all        675        680      0.491      0.518      0.521      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/50      0.96G      1.297      2.071      1.575          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:40<00:00,  8.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.55it/s]\n",
      "                   all        675        680      0.506      0.541      0.494       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/50      0.96G      1.287      2.009      1.579          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:40<00:00,  8.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.64it/s]\n",
      "                   all        675        680      0.432      0.539      0.505      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/50      0.96G      1.261      1.939      1.567          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:41<00:00,  8.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.60it/s]\n",
      "                   all        675        680       0.52      0.665      0.643      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/50      0.96G      1.222      1.833      1.524          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:41<00:00,  8.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.59it/s]\n",
      "                   all        675        680      0.527      0.667      0.624      0.405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/50      0.96G      1.222      1.787       1.52          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:41<00:00,  8.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.63it/s]\n",
      "                   all        675        680      0.576      0.627       0.61      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/50      0.96G        1.2      1.759      1.516          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:40<00:00,  8.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.57it/s]\n",
      "                   all        675        680      0.559      0.632      0.634      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/50      0.96G      1.166       1.69      1.479          0        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:40<00:00,  8.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.61it/s]\n",
      "                   all        675        680      0.561      0.624      0.617      0.392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/50      0.96G      1.155      1.632      1.471          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:41<00:00,  8.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.47it/s]\n",
      "                   all        675        680      0.617      0.702      0.688      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/50      0.96G      1.155      1.595      1.476          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:42<00:00,  8.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.52it/s]\n",
      "                   all        675        680      0.627      0.746      0.715      0.486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/50      0.96G      1.136      1.549      1.472          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:41<00:00,  8.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.58it/s]\n",
      "                   all        675        680      0.668      0.734      0.721      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/50      0.96G      1.125      1.478      1.446          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:41<00:00,  8.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.54it/s]\n",
      "                   all        675        680      0.685      0.707      0.742      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/50      0.96G      1.136      1.477      1.456          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:41<00:00,  8.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.48it/s]\n",
      "                   all        675        680      0.783      0.794       0.81      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/50      0.96G      1.088      1.452      1.417          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:42<00:00,  8.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.54it/s]\n",
      "                   all        675        680       0.71      0.733      0.767      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/50      0.96G      1.083      1.434       1.41          0        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:42<00:00,  8.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.57it/s]\n",
      "                   all        675        680      0.719      0.805      0.805      0.554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/50      0.96G      1.074      1.344      1.389          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:42<00:00,  8.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.59it/s]\n",
      "                   all        675        680       0.66      0.784      0.771      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/50      0.96G       1.07       1.34      1.392          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:42<00:00,  8.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.61it/s]\n",
      "                   all        675        680      0.706      0.777      0.755      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/50      0.96G      1.056        1.3      1.393          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:42<00:00,  8.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.48it/s]\n",
      "                   all        675        680      0.723      0.824      0.824      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/50      0.96G      1.034      1.248      1.361          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:42<00:00,  8.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.47it/s]\n",
      "                   all        675        680      0.759      0.803      0.823      0.577\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/50      0.96G      1.042      1.258      1.375          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:42<00:00,  8.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.44it/s]\n",
      "                   all        675        680      0.765      0.824      0.839      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/50      0.96G      1.033      1.242      1.365          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:43<00:00,  8.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.50it/s]\n",
      "                   all        675        680      0.697      0.848       0.81      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/50      0.96G      1.021      1.233      1.357          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:42<00:00,  8.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.53it/s]\n",
      "                   all        675        680       0.79      0.819      0.849      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/50      0.96G      1.003      1.194       1.34          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:43<00:00,  8.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.51it/s]\n",
      "                   all        675        680      0.772      0.818      0.824      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/50      0.96G      1.005      1.161      1.337          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:43<00:00,  8.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.48it/s]\n",
      "                   all        675        680      0.813      0.788      0.836      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/50      0.96G     0.9986      1.136      1.338          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:43<00:00,  8.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.54it/s]\n",
      "                   all        675        680      0.796      0.835      0.853      0.575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/50      0.96G     0.9815      1.109       1.33          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:44<00:00,  8.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.51it/s]\n",
      "                   all        675        680      0.806      0.892       0.88      0.618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/50      0.96G     0.9656      1.115      1.321          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:43<00:00,  8.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.51it/s]\n",
      "                   all        675        680      0.821      0.831      0.876      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/50      0.96G      0.972      1.097      1.315          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:44<00:00,  8.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.52it/s]\n",
      "                   all        675        680      0.895      0.862      0.916      0.655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/50      0.96G     0.9572      1.059      1.307          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:44<00:00,  8.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.53it/s]\n",
      "                   all        675        680      0.836      0.888      0.903      0.645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/50      0.96G     0.9442      1.028      1.295          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:45<00:00,  8.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.45it/s]\n",
      "                   all        675        680      0.891      0.849      0.897      0.656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/50      0.96G      0.951     0.9998      1.302          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:44<00:00,  8.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.51it/s]\n",
      "                   all        675        680      0.862      0.894      0.914      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/50      0.96G     0.9195     0.9741      1.283          0        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:44<00:00,  8.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.43it/s]\n",
      "                   all        675        680      0.875      0.904      0.927      0.668\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      41/50      0.96G     0.8161     0.5071      1.235          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:28<00:00,  9.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.50it/s]\n",
      "                   all        675        680      0.893        0.9      0.931      0.667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      42/50      0.96G     0.8009     0.4772      1.227          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:30<00:00,  9.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.51it/s]\n",
      "                   all        675        680      0.883       0.89      0.931      0.672\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      43/50      0.96G     0.7806     0.4449      1.203          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:29<00:00,  9.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.51it/s]\n",
      "                   all        675        680      0.913      0.919      0.947      0.685\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      44/50      0.96G     0.7613     0.4289      1.195          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:37<00:00,  9.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.42it/s]\n",
      "                   all        675        680      0.907      0.907      0.932      0.679\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      45/50      0.96G     0.7494     0.4189      1.184          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:29<00:00,  9.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.42it/s]\n",
      "                   all        675        680       0.88      0.886       0.91      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      46/50      0.96G     0.7333     0.4037      1.165          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:28<00:00,  9.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.53it/s]\n",
      "                   all        675        680      0.889       0.88       0.91      0.659\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      47/50      0.96G     0.7056     0.3912      1.149          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:28<00:00,  9.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.44it/s]\n",
      "                   all        675        680      0.906      0.888      0.924      0.666\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      48/50      0.96G     0.6957     0.3824      1.144          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:28<00:00,  9.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.41it/s]\n",
      "                   all        675        680      0.889        0.9      0.924      0.674\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      49/50      0.96G      0.686     0.3666      1.143          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:28<00:00,  9.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 18.37it/s]\n",
      "                   all        675        680      0.902      0.904      0.931      0.681\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      50/50      0.96G     0.6703     0.3601      1.123          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3045/3045 [05:29<00:00,  9.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:18<00:00, 17.83it/s]\n",
      "                   all        675        680      0.909      0.901       0.93      0.674\n",
      "\n",
      "50 epochs completed in 5.010 hours.\n",
      "Optimizer stripped from runs/detect/yolovm_train2/weights/last.pt, 52.1MB\n",
      "Optimizer stripped from runs/detect/yolovm_train2/weights/best.pt, 52.1MB\n",
      "\n",
      "Validating runs/detect/yolovm_train2/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.58 ðŸš€ Python-3.8.10 torch-1.7.0+cu101 CUDA:0 (NVIDIA GeForce GTX 1080, 8111MiB)\n",
      "Model summary (fused): 218 layers, 25854814 parameters, 0 gradients, 78.8 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338/338 [00:19<00:00, 17.75it/s]\n",
      "                   all        675        680      0.913      0.919      0.947      0.685\n",
      "                     0        675         30      0.909      0.867      0.897      0.676\n",
      "                     1        675         25      0.935       0.88      0.955      0.639\n",
      "                    10        675         15      0.865          1      0.965      0.764\n",
      "                    11        675         26      0.777      0.962      0.948      0.714\n",
      "                    12        675         17      0.909          1      0.953      0.592\n",
      "                    13        675         22      0.741      0.818      0.906      0.608\n",
      "                    14        675         25      0.958       0.96      0.986      0.738\n",
      "                    15        675         25      0.925      0.986      0.987       0.71\n",
      "                    16        675         20          1      0.684      0.921      0.675\n",
      "                    17        675         23      0.915      0.957      0.936      0.681\n",
      "                    18        675         26          1       0.78      0.936      0.749\n",
      "                    19        675         20      0.949          1      0.981      0.778\n",
      "                     2        675         25      0.957      0.882      0.979      0.655\n",
      "                    20        675         30      0.934      0.946      0.976       0.75\n",
      "                    21        675         36      0.909          1      0.978      0.701\n",
      "                    22        675         27       0.68      0.963      0.795      0.526\n",
      "                    23        675         29      0.987          1      0.995      0.702\n",
      "                    24        675         32      0.926          1      0.984      0.734\n",
      "                    25        675         31          1      0.973      0.995      0.782\n",
      "                     3        675         40      0.804      0.924       0.88      0.644\n",
      "                     4        675         28          1      0.875      0.978      0.714\n",
      "                     5        675         22      0.857      0.818      0.878      0.601\n",
      "                     6        675         32      0.958      0.938      0.925      0.702\n",
      "                     7        675         20      0.946      0.869      0.968      0.537\n",
      "                     8        675         30      0.913      0.867      0.918      0.665\n",
      "                     9        675         24      0.986      0.958      0.993      0.763\n",
      "Speed: 1.0ms preprocess, 21.6ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/yolovm_train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model.train(data='/home/marwa/handGestur_yolov8/data.yaml', epochs=50, imgsz=640, name='yolovm_train', batch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.58 ðŸš€ Python-3.8.10 torch-1.7.0+cu101 CUDA:0 (NVIDIA GeForce GTX 1080, 8111MiB)\n",
      "Model summary (fused): 218 layers, 25854814 parameters, 0 gradients, 78.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/marwa/handGestur_yolov8/valid/labels.cache... 675 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 675/675 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:17<00:00,  2.44it/s]\n",
      "                   all        675        680      0.914      0.919      0.947      0.685\n",
      "                     0        675         30       0.91      0.867      0.896      0.671\n",
      "                     1        675         25      0.936       0.88      0.955      0.648\n",
      "                    10        675         15      0.866          1      0.965      0.769\n",
      "                    11        675         26      0.777      0.962      0.948      0.715\n",
      "                    12        675         17      0.909          1      0.953      0.594\n",
      "                    13        675         22      0.742      0.818      0.906      0.604\n",
      "                    14        675         25      0.958       0.96      0.986      0.738\n",
      "                    15        675         25      0.961      0.988      0.989      0.718\n",
      "                    16        675         20          1      0.684      0.921      0.664\n",
      "                    17        675         23      0.915      0.957      0.928      0.669\n",
      "                    18        675         26          1      0.779      0.936      0.749\n",
      "                    19        675         20      0.949          1      0.981      0.779\n",
      "                     2        675         25      0.957      0.881      0.979      0.655\n",
      "                    20        675         30      0.934      0.946      0.976      0.744\n",
      "                    21        675         36       0.91          1      0.978      0.703\n",
      "                    22        675         27      0.672      0.963      0.795      0.536\n",
      "                    23        675         29      0.987          1      0.995      0.705\n",
      "                    24        675         32      0.926          1      0.984      0.732\n",
      "                    25        675         31          1      0.973      0.995      0.779\n",
      "                     3        675         40      0.804      0.925       0.88      0.646\n",
      "                     4        675         28          1      0.874      0.978      0.713\n",
      "                     5        675         22      0.859      0.818      0.878      0.605\n",
      "                     6        675         32      0.958      0.938      0.925      0.699\n",
      "                     7        675         20      0.945      0.868      0.969      0.538\n",
      "                     8        675         30      0.913      0.867      0.918      0.662\n",
      "                     9        675         24      0.988      0.958      0.993      0.766\n",
      "Speed: 1.2ms preprocess, 17.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object at 0x7f5403cc8b20>\n",
       "fitness: 0.7109267207620984\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([      0.671,      0.6481,     0.76924,     0.71537,     0.59448,     0.60401,     0.73783,      0.7184,     0.66432,     0.66885,      0.7488,     0.77907,     0.65549,     0.74429,     0.70288,     0.53637,     0.70456,     0.73164,     0.77917,     0.64553,      0.7135,     0.60534,     0.69911,     0.53782,\n",
       "            0.6623,     0.76596])\n",
       "names: {0: '0', 1: '1', 2: '10', 3: '11', 4: '12', 5: '13', 6: '14', 7: '15', 8: '16', 9: '17', 10: '18', 11: '19', 12: '2', 13: '20', 14: '21', 15: '22', 16: '23', 17: '24', 18: '25', 19: '3', 20: '4', 21: '5', 22: '6', 23: '7', 24: '8', 25: '9'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9144858661549732, 'metrics/recall(B)': 0.9193485238933212, 'metrics/mAP50(B)': 0.9465374246903099, 'metrics/mAP50-95(B)': 0.6847477536589638, 'fitness': 0.7109267207620984}\n",
       "save_dir: PosixPath('runs/detect/val')\n",
       "speed: {'preprocess': 1.2436849099618417, 'inference': 17.43098223650897, 'loss': 0.0005386493824146412, 'postprocess': 2.49869876437717}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO('/home/marwa/handGestur_yolov8/runs/detect/yolovm_train2/weights/best.pt')\n",
    "model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 12, 18.8ms\n",
      "Speed: 0.9ms preprocess, 18.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 18, 19.0ms\n",
      "Speed: 1.0ms preprocess, 19.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7, 19.1ms\n",
      "Speed: 0.9ms preprocess, 19.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8, 19.7ms\n",
      "Speed: 0.9ms preprocess, 19.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 21.4ms\n",
      "Speed: 0.9ms preprocess, 21.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 18.0ms\n",
      "Speed: 0.9ms preprocess, 18.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 17.7ms\n",
      "Speed: 1.0ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 20.0ms\n",
      "Speed: 1.0ms preprocess, 20.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.2ms\n",
      "Speed: 1.1ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.9ms\n",
      "Speed: 1.0ms preprocess, 17.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 19, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2, 18.0ms\n",
      "Speed: 1.1ms preprocess, 18.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 24, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.9ms\n",
      "Speed: 1.1ms preprocess, 17.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 17, 18.0ms\n",
      "Speed: 1.1ms preprocess, 18.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 18, 17.9ms\n",
      "Speed: 1.0ms preprocess, 17.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8, 18.1ms\n",
      "Speed: 1.0ms preprocess, 18.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 14, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 10, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 3s, 17.9ms\n",
      "Speed: 0.9ms preprocess, 17.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 2s, 17.3ms\n",
      "Speed: 1.1ms preprocess, 17.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 17.3ms\n",
      "Speed: 1.0ms preprocess, 17.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 17.7ms\n",
      "Speed: 1.0ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 17.7ms\n",
      "Speed: 1.0ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 1 13, 18.2ms\n",
      "Speed: 1.2ms preprocess, 18.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 18.8ms\n",
      "Speed: 1.0ms preprocess, 18.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.4ms\n",
      "Speed: 1.1ms preprocess, 17.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3, 17.1ms\n",
      "Speed: 0.9ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 1 20, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8, 17.3ms\n",
      "Speed: 1.4ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 10, 17.8ms\n",
      "Speed: 0.8ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5, 17.9ms\n",
      "Speed: 1.1ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 17.5ms\n",
      "Speed: 1.1ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 17.9ms\n",
      "Speed: 0.9ms preprocess, 17.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 1 9, 17.7ms\n",
      "Speed: 1.0ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5, 17.9ms\n",
      "Speed: 1.0ms preprocess, 17.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.9ms\n",
      "Speed: 1.0ms preprocess, 17.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 3s, 1 4, 17.9ms\n",
      "Speed: 0.9ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 4s, 17.8ms\n",
      "Speed: 1.1ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.6ms\n",
      "Speed: 0.8ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 17.6ms\n",
      "Speed: 1.0ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 17.2ms\n",
      "Speed: 0.9ms preprocess, 17.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.0ms\n",
      "Speed: 1.1ms preprocess, 17.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 10, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 15, 17.2ms\n",
      "Speed: 1.0ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 17, 17.8ms\n",
      "Speed: 1.0ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 18, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 15, 17.6ms\n",
      "Speed: 1.0ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 1 3, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2, 1 22, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 15, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.1ms\n",
      "Speed: 0.9ms preprocess, 17.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 18, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.2ms\n",
      "Speed: 1.0ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 17.2ms\n",
      "Speed: 1.2ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5, 17.4ms\n",
      "Speed: 1.1ms preprocess, 17.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 1 23, 17.4ms\n",
      "Speed: 1.2ms preprocess, 17.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 18.0ms\n",
      "Speed: 0.9ms preprocess, 18.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 16, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 1 5, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 18.1ms\n",
      "Speed: 1.0ms preprocess, 18.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 24, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 16s, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 22s, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.2ms\n",
      "Speed: 1.0ms preprocess, 17.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.4ms\n",
      "Speed: 1.1ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 17, 17.2ms\n",
      "Speed: 1.1ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 24s, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 17.9ms\n",
      "Speed: 1.1ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.8ms\n",
      "Speed: 0.8ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 10, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 19, 17.8ms\n",
      "Speed: 1.1ms preprocess, 17.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 16s, 17.9ms\n",
      "Speed: 0.9ms preprocess, 17.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 17.9ms\n",
      "Speed: 1.1ms preprocess, 17.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.5ms\n",
      "Speed: 0.8ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 18, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5, 20.5ms\n",
      "Speed: 1.0ms preprocess, 20.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 18.1ms\n",
      "Speed: 0.9ms preprocess, 18.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 16, 17.5ms\n",
      "Speed: 1.1ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3, 17.8ms\n",
      "Speed: 1.1ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8, 18.0ms\n",
      "Speed: 0.9ms preprocess, 18.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2, 17.5ms\n",
      "Speed: 0.8ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 18, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 17.2ms\n",
      "Speed: 0.8ms preprocess, 17.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 14, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 1 13, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 1 4, 17.9ms\n",
      "Speed: 1.0ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 8s, 17.2ms\n",
      "Speed: 1.0ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 16, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3, 4 8s, 17.1ms\n",
      "Speed: 0.8ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 17.0ms\n",
      "Speed: 0.9ms preprocess, 17.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 17.5ms\n",
      "Speed: 0.8ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 19, 17.0ms\n",
      "Speed: 0.8ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 16, 1 5, 16.7ms\n",
      "Speed: 1.0ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 18, 17.7ms\n",
      "Speed: 0.8ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 18, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 16, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 1 13, 17.3ms\n",
      "Speed: 0.8ms preprocess, 17.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 17.3ms\n",
      "Speed: 0.8ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 17, 17.2ms\n",
      "Speed: 0.9ms preprocess, 17.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 16, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 0s, 17.3ms\n",
      "Speed: 2.2ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 18, 17.8ms\n",
      "Speed: 0.8ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 24, 1 8, 17.2ms\n",
      "Speed: 0.9ms preprocess, 17.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 16s, 17.1ms\n",
      "Speed: 1.0ms preprocess, 17.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.2ms\n",
      "Speed: 0.9ms preprocess, 17.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 18.1ms\n",
      "Speed: 0.9ms preprocess, 18.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 15, 1 2, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.5ms\n",
      "Speed: 0.8ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 19.7ms\n",
      "Speed: 0.9ms preprocess, 19.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 18.0ms\n",
      "Speed: 0.9ms preprocess, 18.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 19, 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 2 22s, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 17.6ms\n",
      "Speed: 0.8ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2, 17.4ms\n",
      "Speed: 1.1ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 24, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 17.4ms\n",
      "Speed: 0.8ms preprocess, 17.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 17.1ms\n",
      "Speed: 0.9ms preprocess, 17.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 17, 17.1ms\n",
      "Speed: 1.1ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 16.9ms\n",
      "Speed: 0.8ms preprocess, 16.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 24, 17.3ms\n",
      "Speed: 1.3ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 18.1ms\n",
      "Speed: 0.8ms preprocess, 18.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 15, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 18, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 16s, 17.7ms\n",
      "Speed: 0.8ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 3s, 18.0ms\n",
      "Speed: 0.9ms preprocess, 18.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 15, 18.1ms\n",
      "Speed: 0.9ms preprocess, 18.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 10, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 14, 17.6ms\n",
      "Speed: 1.0ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 1 5, 17.9ms\n",
      "Speed: 1.1ms preprocess, 17.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 1 9, 17.9ms\n",
      "Speed: 1.0ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.8ms\n",
      "Speed: 0.8ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 1 20, 17.7ms\n",
      "Speed: 0.8ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 15, 17.9ms\n",
      "Speed: 1.0ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 24, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 10, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7, 17.4ms\n",
      "Speed: 1.1ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 1 13, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 17, 1 20, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 17.3ms\n",
      "Speed: 1.1ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 17.6ms\n",
      "Speed: 1.0ms preprocess, 17.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 17.4ms\n",
      "Speed: 0.8ms preprocess, 17.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 14, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5, 17.5ms\n",
      "Speed: 0.8ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 24, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 1 22, 17.6ms\n",
      "Speed: 1.0ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 5s, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6, 1 7, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6, 18.0ms\n",
      "Speed: 0.9ms preprocess, 18.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 15, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 19, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 16, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 2s, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.7ms\n",
      "Speed: 1.0ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 10, 17.5ms\n",
      "Speed: 0.8ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3, 17.6ms\n",
      "Speed: 0.8ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 15s, 18.1ms\n",
      "Speed: 0.9ms preprocess, 18.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3, 1 4, 4 8s, 17.9ms\n",
      "Speed: 0.9ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 3s, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 2s, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 16, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 24s, 1 8, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.4ms\n",
      "Speed: 0.8ms preprocess, 17.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 19, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 17.9ms\n",
      "Speed: 1.1ms preprocess, 17.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 10, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 1 9, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 17, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7, 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 24, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 19, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 18.2ms\n",
      "Speed: 0.8ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 18.1ms\n",
      "Speed: 1.1ms preprocess, 18.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 17, 17.7ms\n",
      "Speed: 1.0ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 15, 17.6ms\n",
      "Speed: 0.8ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 16s, 17.2ms\n",
      "Speed: 0.8ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 18, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 1 21, 17.2ms\n",
      "Speed: 1.1ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.6ms\n",
      "Speed: 1.0ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 17.2ms\n",
      "Speed: 0.8ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 24, 17.9ms\n",
      "Speed: 0.9ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 19, 17.4ms\n",
      "Speed: 0.8ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 17.7ms\n",
      "Speed: 0.8ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 17.5ms\n",
      "Speed: 0.8ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 2s, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 1 5, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.4ms\n",
      "Speed: 0.8ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 17.5ms\n",
      "Speed: 0.8ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 15, 17.1ms\n",
      "Speed: 0.9ms preprocess, 17.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.6ms\n",
      "Speed: 1.0ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 1 13, 17.6ms\n",
      "Speed: 1.0ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 17.9ms\n",
      "Speed: 0.9ms preprocess, 17.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.3ms\n",
      "Speed: 1.7ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5, 17.5ms\n",
      "Speed: 1.1ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 18, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 18.3ms\n",
      "Speed: 0.9ms preprocess, 18.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 20.7ms\n",
      "Speed: 0.9ms preprocess, 20.7ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8, 17.3ms\n",
      "Speed: 1.0ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.3ms\n",
      "Speed: 0.8ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 17.9ms\n",
      "Speed: 0.9ms preprocess, 17.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2, 1 6, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 17.6ms\n",
      "Speed: 0.8ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 19, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 17, 17.5ms\n",
      "Speed: 0.8ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.4ms\n",
      "Speed: 0.8ms preprocess, 17.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.7ms\n",
      "Speed: 0.8ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 14, 17.1ms\n",
      "Speed: 0.9ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7, 17.2ms\n",
      "Speed: 0.8ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 17.2ms\n",
      "Speed: 0.9ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 17.3ms\n",
      "Speed: 1.0ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.5ms\n",
      "Speed: 0.8ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 19, 18.2ms\n",
      "Speed: 0.9ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8, 17.3ms\n",
      "Speed: 0.8ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.4ms\n",
      "Speed: 0.8ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 10, 1 14, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5, 17.3ms\n",
      "Speed: 0.8ms preprocess, 17.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.1ms\n",
      "Speed: 0.8ms preprocess, 17.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 22s, 17.2ms\n",
      "Speed: 0.8ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 10, 1 21, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 14, 17.8ms\n",
      "Speed: 1.0ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 17.3ms\n",
      "Speed: 1.0ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 4s, 17.2ms\n",
      "Speed: 0.9ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 0s, 17.2ms\n",
      "Speed: 0.9ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.4ms\n",
      "Speed: 1.1ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 17.2ms\n",
      "Speed: 1.0ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 16, 17.7ms\n",
      "Speed: 0.8ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 24, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 18.1ms\n",
      "Speed: 0.9ms preprocess, 18.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 10, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 1 20, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3, 17.5ms\n",
      "Speed: 0.8ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 1 13, 17.6ms\n",
      "Speed: 0.8ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 19, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 14, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6, 18.1ms\n",
      "Speed: 0.9ms preprocess, 18.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 23s, 17.8ms\n",
      "Speed: 0.8ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 18.6ms\n",
      "Speed: 1.0ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7, 17.8ms\n",
      "Speed: 1.1ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 1 13, 17.3ms\n",
      "Speed: 1.0ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 1 20, 17.3ms\n",
      "Speed: 1.0ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.2ms\n",
      "Speed: 1.1ms preprocess, 17.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.9ms\n",
      "Speed: 0.8ms preprocess, 17.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 17.7ms\n",
      "Speed: 1.0ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 22s, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 1 22, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 19, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 18, 17.6ms\n",
      "Speed: 0.8ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 13, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.4ms\n",
      "Speed: 0.8ms preprocess, 17.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.1ms\n",
      "Speed: 1.1ms preprocess, 17.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 19, 18.0ms\n",
      "Speed: 0.8ms preprocess, 18.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 17.7ms\n",
      "Speed: 1.0ms preprocess, 17.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2, 17.9ms\n",
      "Speed: 1.0ms preprocess, 17.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 14, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 18, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.7ms\n",
      "Speed: 0.8ms preprocess, 17.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 24, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 5s, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.8ms\n",
      "Speed: 0.8ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 17, 17.3ms\n",
      "Speed: 0.8ms preprocess, 17.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 0, 1 24, 17.2ms\n",
      "Speed: 0.9ms preprocess, 17.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2, 17.6ms\n",
      "Speed: 0.8ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 18.1ms\n",
      "Speed: 1.0ms preprocess, 18.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 17.8ms\n",
      "Speed: 0.8ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 17.7ms\n",
      "Speed: 1.0ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 11, 17.7ms\n",
      "Speed: 1.1ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 23, 18.2ms\n",
      "Speed: 1.0ms preprocess, 18.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 17.8ms\n",
      "Speed: 0.8ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 20, 17.6ms\n",
      "Speed: 1.0ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 14, 17.6ms\n",
      "Speed: 0.8ms preprocess, 17.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 14, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5, 17.6ms\n",
      "Speed: 0.8ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.5ms\n",
      "Speed: 0.9ms preprocess, 17.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 24, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8, 17.4ms\n",
      "Speed: 0.9ms preprocess, 17.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 17.2ms\n",
      "Speed: 0.9ms preprocess, 17.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.2ms\n",
      "Speed: 0.8ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7, 17.4ms\n",
      "Speed: 1.2ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 14, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 24, 17.9ms\n",
      "Speed: 1.0ms preprocess, 17.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 21, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 1 7, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 1, 17.6ms\n",
      "Speed: 0.9ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 25, 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8, 17.5ms\n",
      "Speed: 1.0ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 14, 17.3ms\n",
      "Speed: 0.9ms preprocess, 17.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 12, 1 13, 17.8ms\n",
      "Speed: 0.9ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 22, 17.7ms\n",
      "Speed: 0.8ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 5s, 17.7ms\n",
      "Speed: 0.9ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9, 17.7ms\n",
      "Speed: 1.0ms preprocess, 17.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import pathlib as path\n",
    "import glob\n",
    "model = YOLO('/home/marwa/handGestur_yolov8/runs/detect/yolovm_train2/weights/best.pt')\n",
    "frames_path = '/home/marwa/handGestur_yolov8/test/frames'\n",
    "\n",
    "# read image directory\n",
    "surcefiles = '/home/marwa/handGestur_yolov8/test/images/*.jpg'\n",
    "images = path.Path(surcefiles).glob('*.jpg')\n",
    "class_name_dict = {0:'A', 1:'B', 2:'K', 3:'L', 4:'M', 5:'N', 6:'O', 7:'P', 8:'Q', 9:'R', 10:'S', 11:'T', 12:'C', 13:'U', 14:'V', 15:'W', 16:'X', 17:'Y', 18:'Z', 19:'D', 20:'E', 21:'F', 22:'G', 23:'H', 24:'I', 25:'J'}\n",
    "colors = [(89, 161, 197),(67, 161, 255),(19, 222, 24),(186, 55, 2),(167, 146, 11),(190, 76, 98),(130, 172, 179),(115, 209, 128),(204, 79, 135),(136, 126, 185),(209, 213, 45),(44, 52, 10),(101, 158, 121),(179, 124, 12),(25, 33, 189),(45, 115, 11),(73, 197, 184),(62, 225, 221),(32, 46, 52),(20, 165, 16),(54, 15, 57),(12, 150, 9),(10, 46, 99),(94, 89, 46),(48, 37, 106),(42, 10, 96),(7, 164, 128),(98, 213, 120),(40, 5, 219),(54, 25, 150),(251, 74, 172),(0, 236, 196),(21, 104, 190),(226, 74, 232),(120, 67, 25),(191, 106, 197),(8, 15, 134),(21, 2, 1),(142, 63, 109),(133, 148, 146),(187, 77, 253),(155, 22, 122),(218, 130, 77),(164, 102, 79),(43, 152, 125),(185, 124, 151),(95, 159, 238),(128, 89, 85),(228, 6, 60),(6, 41, 210),(11, 1, 133),(30, 96, 58),(230, 136, 109),(126, 45, 174),(164, 63, 165),(32, 111, 29),(232, 40, 70),(55, 31, 198),(148, 211, 129),(10, 186, 211),(181, 201, 94),(55, 35, 92),(129, 140, 233),(70, 250, 116),(61, 209, 152),(216, 21, 138),(100, 0, 176),(3, 42, 70),(151, 13, 44),(216, 102, 88),(125, 216, 93),(171, 236, 47),(253, 127, 103),(205, 137, 244),(193, 137, 224),(36, 152, 214),(17, 50, 238),(154, 165, 67),(114, 129, 60),(119, 24, 48),(73, 8, 110)]\n",
    "\n",
    "i=0\n",
    "for image in glob.glob(surcefiles):\n",
    "    # print(\"image is -------------\",image)\n",
    "    frame = cv2.imread(image)\n",
    "    # print(\"image is -------------\",frame)\n",
    "    # cv2.imshow('frame',frame)\n",
    "    # cv2.waitKey(1)\n",
    "    results = model.predict(frame, hide_labels=True, show=False, imgsz=640)[0]\n",
    "    for result in results.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = result\n",
    "            label = \"{}:{:.2f}\".format(class_name_dict[int(class_id)], score*100)\n",
    "            lw = max(round(sum(frame.shape) / 2 * 0.003), 2)\n",
    "            p1, p2 = (int(x1), int(y1)), (int(x2), int(y2))\n",
    "            color = colors[int(class_id)]\n",
    "            cv2.rectangle(frame, p1, p2, color, thickness=lw, lineType=cv2.LINE_AA)\n",
    "            tf = max(lw - 1, 1)  # font thickness\n",
    "            w, h = cv2.getTextSize(label, 0, fontScale=lw / 3, thickness=tf)[0]  # text width, height\n",
    "            outside = p1[1] - h >= 3\n",
    "            p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "            frame = cv2.rectangle(frame, p1, p2, color, -1, cv2.LINE_AA)            \n",
    "            frame = cv2.putText(frame,label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),0,lw / 3,(255,255,255),thickness=tf,lineType=cv2.LINE_AA)   \n",
    "    frame_name = 'Frame'+str(i)+'.jpg'\n",
    "    cv2.imwrite(os.path.join(frames_path,frame_name), frame)\n",
    "    i+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame number.............. ['/home/marwa/handGestur_yolov8/test/frames/Frame0.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame1.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame2.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame3.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame4.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame5.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame6.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame7.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame8.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame9.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame10.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame11.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame12.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame13.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame14.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame15.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame16.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame17.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame18.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame19.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame20.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame21.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame22.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame23.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame24.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame25.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame26.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame27.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame28.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame29.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame30.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame31.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame32.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame33.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame34.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame35.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame36.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame37.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame38.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame39.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame40.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame41.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame42.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame43.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame44.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame45.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame46.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame48.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame49.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame50.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame52.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame53.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame54.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame55.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame56.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame57.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame58.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame59.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame60.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame61.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame62.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame63.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame64.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame65.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame66.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame68.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame72.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame73.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame74.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame75.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame77.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame78.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame79.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame81.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame82.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame83.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame84.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame85.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame86.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame87.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame88.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame89.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame90.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame91.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame92.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame93.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame94.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame95.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame96.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame97.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame98.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame99.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame100.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame101.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame102.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame103.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame104.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame105.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame106.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame107.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame108.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame109.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame110.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame111.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame112.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame113.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame114.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame115.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame116.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame117.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame118.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame119.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame121.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame122.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame123.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame124.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame125.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame126.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame127.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame128.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame129.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame130.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame132.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame133.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame134.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame135.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame136.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame137.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame138.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame140.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame141.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame142.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame143.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame144.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame145.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame146.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame147.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame148.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame149.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame150.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame151.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame153.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame155.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame156.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame157.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame158.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame159.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame160.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame161.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame162.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame163.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame164.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame165.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame166.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame168.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame169.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame170.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame171.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame172.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame173.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame174.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame175.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame176.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame177.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame178.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame179.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame180.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame181.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame182.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame183.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame184.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame185.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame186.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame187.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame188.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame189.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame190.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame191.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame192.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame193.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame195.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame196.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame197.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame198.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame199.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame200.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame203.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame204.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame205.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame206.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame207.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame208.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame209.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame210.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame211.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame213.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame214.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame216.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame217.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame218.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame219.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame220.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame221.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame222.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame223.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame224.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame225.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame226.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame227.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame228.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame229.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame230.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame232.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame233.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame234.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame235.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame237.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame238.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame239.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame240.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame241.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame242.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame243.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame244.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame245.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame246.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame247.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame248.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame249.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame250.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame251.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame252.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame253.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame254.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame255.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame256.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame257.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame258.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame259.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame260.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame261.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame262.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame263.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame264.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame265.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame266.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame267.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame268.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame269.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame270.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame271.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame272.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame273.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame274.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame275.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame276.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame277.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame278.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame280.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame281.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame282.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame283.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame284.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame285.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame286.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame287.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame288.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame289.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame290.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame291.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame292.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame293.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame294.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame295.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame296.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame297.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame298.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame299.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame300.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame301.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame302.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame303.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame304.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame305.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame306.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame307.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame308.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame309.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame310.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame311.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame312.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame313.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame314.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame315.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame316.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame317.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame318.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame319.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame320.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame322.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame323.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame324.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame325.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame326.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame327.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame328.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame329.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame330.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame331.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame332.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame333.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame334.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame335.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame336.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame337.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame338.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame339.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame340.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame341.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame342.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame343.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame344.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame345.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame346.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame347.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame348.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame349.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame350.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame351.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame352.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame353.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame354.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame355.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame356.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame357.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame358.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame359.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame360.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame361.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame362.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame363.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame364.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame365.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame366.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame367.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame368.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame369.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame370.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame371.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame372.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame373.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame374.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame375.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame376.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame377.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame378.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame379.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame380.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame381.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame382.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame383.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame384.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame385.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame386.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame387.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame388.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame389.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame390.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame391.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame392.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame393.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame394.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame395.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame396.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame397.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame398.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame399.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame400.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame401.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame402.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame403.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame404.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame405.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame406.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame407.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame408.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame409.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame410.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame411.jpg', '/home/marwa/handGestur_yolov8/test/frames/Frame412.jpg']\n",
      "sequence clip <moviepy.video.io.ImageSequenceClip.ImageSequenceClip object at 0x7f91b43179a0>\n",
      "Moviepy - Building video /home/marwa/handGestur_yolov8/runs/myvideo_handGesture.mp4.\n",
      "Moviepy - Writing video /home/marwa/handGestur_yolov8/runs/myvideo_handGesture.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/marwa/handGestur_yolov8/runs/myvideo_handGesture.mp4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import natsort\n",
    "img_path = '/home/marwa/handGestur_yolov8/test/frames'\n",
    "video_path = '/home/marwa/Self Driving Caryolov8/test/video1.mp3'\n",
    "img_array = []\n",
    "from moviepy.editor import *\n",
    "import moviepy.video.io.ImageSequenceClip\n",
    "image_folder=img_path\n",
    "fps=1\n",
    "\n",
    "image_files = [os.path.join(image_folder,img)\n",
    "                for img in natsort.natsorted(os.listdir(image_folder))]\n",
    "\n",
    "# image_files= image_files[0:100]\n",
    "print(\"frame number..............\",image_files)\n",
    "clip = ImageSequenceClip(image_files, fps=1)\n",
    "print(\"sequence clip\",clip)\n",
    "# clip = ImageSequenceClip([os.path.join(img_path,'Frame0.jpg'), os.path.join(img_path,'Frame1.jpg'),os.path.join(img_path,'Frame2.jpg'),os.path.join(img_path,'Frame3.jpg'),os.path.join(img_path,'Frame4.jpg'),os.path.join(img_path,'Frame5.jpg')\n",
    "#                           ,os.path.join(img_path,'Frame6.jpg'),os.path.join(img_path,'Frame7.jpg'),os.path.join(img_path,'Frame8.jpg'),os.path.join(img_path,'Frame9.jpg'),os.path.join(img_path,'Frame10.jpg'),os.path.join(img_path,'Frame11.jpg')],fps=1)\n",
    "# print(clip)\n",
    "\n",
    "clip.write_videofile('/home/marwa/handGestur_yolov8/runs/myvideo_handGesture.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
